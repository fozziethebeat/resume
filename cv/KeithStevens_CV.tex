%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% Simple LaTeX CV Template %%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% NOTE: If you find that it says                                     %%
%%                                                                    %%
%%                           1 of ??                                  %%
%%                                                                    %%
%% at the bottom of your first page, this means that the AUX file     %%
%% was not available when you ran LaTeX on this source. Simply RERUN  %%
%% LaTeX to get the ``??'' replaced with the number of the last page  %%
%% of the document. The AUX file will be generated on the first run   %%
%% of LaTeX and used on the second run to fill in all of the          %%
%% references.                                                        %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%% Document Setup %%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Don't like 10pt? Try 11pt or 12pt
\documentclass[10pt]{article}

% This is a helpful package that puts math inside length specifications
\usepackage{calc}

% Simpler bibsection for CV sections
% (thanks to natbib for inspiration)
\makeatletter
\newlength{\bibhang}
\setlength{\bibhang}{1em}
\newlength{\bibsep}
 {\@listi \global\bibsep\itemsep \global\advance\bibsep by\parsep}
\newenvironment{bibsection}%
        {\begin{list}{}{%
       \setlength{\leftmargin}{\bibhang}%
       \setlength{\itemindent}{-\leftmargin}%
       \setlength{\itemsep}{\bibsep}%
       \setlength{\parsep}{\z@}%
        \setlength{\partopsep}{0pt}%
        \setlength{\topsep}{0pt}}}
        {\end{list}\vspace{-.6\baselineskip}}
\makeatother

% Layout: Puts the section titles on left side of page
\reversemarginpar

%
%         PAPER SIZE, PAGE NUMBER, AND DOCUMENT LAYOUT NOTES:
%
% The next \usepackage line changes the layout for CV style section
% headings as marginal notes. It also sets up the paper size as either
% letter or A4. By default, letter was used. If A4 paper is desired,
% comment out the letterpaper lines and uncomment the a4paper lines.
%
% As you can see, the margin widths and section title widths can be
% easily adjusted.
%
% ALSO: Notice that the includefoot option can be commented OUT in order
% to put the PAGE NUMBER *IN* the bottom margin. This will make the
% effective text area larger.
%
% IF YOU WISH TO REMOVE THE ``of LASTPAGE'' next to each page number,
% see the note about the +LP and -LP lines below. Comment out the +LP
% and uncomment the -LP.
%
% IF YOU WISH TO REMOVE PAGE NUMBERS, be sure that the includefoot line
% is uncommented and ALSO uncomment the \pagestyle{empty} a few lines
% below.
%

%% Use these lines for letter-sized paper
\usepackage[paper=letterpaper,
            %includefoot, % Uncomment to put page number above margin
            marginparwidth=1.2in,     % Length of section titles
            marginparsep=.05in,       % Space between titles and text
            margin=1in,               % 1 inch margins
            includemp]{geometry}

%% Use these lines for A4-sized paper
%\usepackage[paper=a4paper,
%            %includefoot, % Uncomment to put page number above margin
%            marginparwidth=30.5mm,    % Length of section titles
%            marginparsep=1.5mm,       % Space between titles and text
%            margin=25mm,              % 25mm margins
%            includemp]{geometry}

%% More layout: Get rid of indenting throughout entire document
\setlength{\parindent}{0in}

\usepackage[shortlabels]{enumitem}

%% Reference the last page in the page number
%
% NOTE: comment the +LP line and uncomment the -LP line to have page
%       numbers without the ``of ##'' last page reference)
%
% NOTE: uncomment the \pagestyle{empty} line to get rid of all page
%       numbers (make sure includefoot is commented out above)
%
\usepackage{fancyhdr,lastpage}
\pagestyle{fancy}
%\pagestyle{empty}      % Uncomment this to get rid of page numbers
\fancyhf{}\renewcommand{\headrulewidth}{0pt}
\fancyfootoffset{\marginparsep+\marginparwidth}
\newlength{\footpageshift}
\setlength{\footpageshift}
          {0.5\textwidth+0.5\marginparsep+0.5\marginparwidth-2in}
\lfoot{\hspace{\footpageshift}%
       \parbox{4in}{\, \hfill %
                    \arabic{page} of \protect\pageref*{LastPage} % +LP
%                    \arabic{page}                               % -LP
                    \hfill \,}}

% Finally, give us PDF bookmarks
\usepackage{color,hyperref}
\definecolor{darkblue}{rgb}{0.0,0.0,0.3}
\hypersetup{colorlinks,breaklinks,
            linkcolor=darkblue,urlcolor=darkblue,
            anchorcolor=darkblue,citecolor=darkblue}

%%%%%%%%%%%%%%%%%%%%%%%% End Document Setup %%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%% Helper Commands %%%%%%%%%%%%%%%%%%%%%%%%%%%%

% The title (name) with a horizontal rule under it
% (optional argument typesets an object right-justified across from name
%  as well)
%
% Usage: \makeheading{name}
%        OR
%        \makeheading[right_object]{name}
%
% Place at top of document. It should be the first thing.
% If ``right_object'' is provided in the square-braced optional
% argument, it will be right justified on the same line as ``name'' at
% the top of the CV. For example:
%
%       \makeheading[\emph{Curriculum vitae}]{Your Name}
%
% will put an emphasized ``Curriculum vitae'' at the top of the document
% as a title. Likewise, a picture could be included:
%
%   \makeheading[\includegraphics[height=1.5in]{my_picutre}]{Your Name}
%
% the picture will be flush right across from the name.
\newcommand{\makeheading}[2][]%
        {\hspace*{-\marginparsep minus \marginparwidth}%
         \begin{minipage}[t]{\textwidth+\marginparwidth+\marginparsep}%
             {\large \bfseries #2 \hfill #1}\\[-0.15\baselineskip]%
                 \rule{\columnwidth}{1pt}%
         \end{minipage}}

% The section headings
%
% Usage: \section{section name}
\renewcommand{\section}[1]{\pagebreak[3]%
    \hyphenpenalty=10000%
    \vspace{1.3\baselineskip}%
    \phantomsection\addcontentsline{toc}{section}{#1}%
    \noindent\llap{\scshape\smash{\parbox[t]{\marginparwidth}{\raggedright #1}}}%
    \vspace{-\baselineskip}\par}

% An itemize-style list with lots of space between items
\newenvironment{outerlist}[1][\enskip\textbullet]%
        {\begin{itemize}[#1,leftmargin=*]}{\end{itemize}%
         \vspace{-.6\baselineskip}}

% An environment IDENTICAL to outerlist that has better pre-list spacing
% when used as the first thing in a \section
\newenvironment{lonelist}[1][\enskip\textbullet]%
        {\begin{list}{#1}{%
        \setlength{\partopsep}{0pt}%
        \setlength{\topsep}{0pt}}}
        {\end{list}\vspace{-.6\baselineskip}}

% An itemize-style list with little space between items
\newenvironment{innerlist}[1][\enskip\textbullet]%
        {\begin{itemize}[#1,leftmargin=*,parsep=0pt,itemsep=0pt,topsep=0pt,partopsep=0pt]}
        {\end{itemize}}

% An environment IDENTICAL to innerlist that has better pre-list spacing
% when used as the first thing in a \section
\newenvironment{loneinnerlist}[1][\enskip\textbullet]%
        {\begin{itemize}[#1,leftmargin=*,parsep=0pt,itemsep=0pt,topsep=0pt,partopsep=0pt]}
        {\end{itemize}\vspace{-.6\baselineskip}}

% To add some paragraph space between lines.
% This also tells LaTeX to preferably break a page on one of these gaps
% if there is a needed pagebreak nearby.
\newcommand{\blankline}{\quad\pagebreak[3]}
\newcommand{\halfblankline}{\quad\vspace{-0.5\baselineskip}\pagebreak[3]}

% Uses hyperref to link DOI
\newcommand\doilink[1]{\href{http://dx.doi.org/#1}{#1}}
\newcommand\doi[1]{doi:\doilink{#1}}

% For \url{SOME_URL}, links SOME_URL to the url SOME_URL
\providecommand*\url[1]{\href{#1}{#1}}
% Same as above, but pretty-prints SOME_URL in teletype fixed-width font
\renewcommand*\url[1]{\href{#1}{\texttt{#1}}}

% For \email{ADDRESS}, links ADDRESS to the url mailto:ADDRESS
\providecommand*\email[1]{\href{mailto:#1}{#1}}
% Same as above, but pretty-prints ADDRESS in teletype fixed-width font
%\renewcommand*\email[1]{\href{mailto:#1}{\texttt{#1}}}

%\providecommand\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
%    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
%\providecommand\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
%    \TeX}}
\providecommand\BibTeX{{B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    \TeX}}
\providecommand\Matlab{\textsc{Matlab}}

%%%%%%%%%%%%%%%%%%%%%%%% End Helper Commands %%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%% Begin CV Document %%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\makeheading{Keith D. Stevens}

\section{Contact Information}

% NOTE: Mind where the & separators and \\ breaks are in the following
%       table.
%
% ALSO: \rcollength is the width of the right column of the table
%       (adjust it to your liking; default is 1.85in).
%
\newlength{\rcollength}\setlength{\rcollength}{1.85in}%
%
\begin{tabular}[t]{@{}p{\textwidth-\rcollength}p{\rcollength}}
\href{http://iscr.llnl.gov/}%
     {Institute for Scientific Computing Research} & \textit{Mobile:} +1-805-433-2295\\
\href{http://www.llnl.gov/}{Lawrence Livermore National Lab}
7000 East Ave,       & \email{fozziethebeat@gmail.com}\\
Livermore, CA 94551  & 
\href{http://fozziethebeat.github.com}{http://fozziethebeat.github.com} \\
\end{tabular}

\section{Objective}

Placement in a development and/or research position centered around distributed
semantics and unsupervised learning, along with applying current theories on
these topics to web search or other human oriented data exploration tasks.

\section{Research Focus}

My research focuses on the unsupervised acquisition of word senses and the
automated evaluation of related models.  Word sense acquisition, or Word Sense
Induction (WSI), attempts to use contextual information to learn distinct word
senses as they appear in large corpora.  My PhD centers around using Ensemble
Clustering to improve Word Sense Induction by combining multiple models into a
single system.  Using this approach, I not only find ways to find some
improvement over existing approaches, I use the added knowledge created by
multiple models to survey existing state of the art methods and evaluate the
effectiveness of current evaluation techniques.  Beyond Word Sense Induction, I
am interested in automated approaches for navigating large document sets based
on semantic knowledge and interests.

\section{Education}

\href{http://www.ucla.edu/}{\textbf{University of California, Los Angeles}},
Los Angeles, California USA
\begin{outerlist}

\item[] Ph.D.,
        \href{http://www.cs.ucla.edu/}
             {Computer Science},
             In Progress
        \begin{innerlist}
        \item Thesis Topic: \emph{Ensemble Clustering and Word Sense Induction:
        when is it right for Word sense Induction?}
        \item Adviser:
              \href{http://www.cs.ucla.edu/~dyer/}
                   {Professor Michael G.~Dyer}
        \item Area of Study: Computational Linguistics
        \end{innerlist}

\item[] M.S.,
        \href{http://www.cs.ucla.edu/}
             {Computer Science}, October 2011
        \begin{innerlist}
        \item Thesis Topic: \emph{Extending Word Sense Induction with waiting
        and depending}
        \item Adviser:
              \href{http://www.cs.ucla.edu/~dyer/}
                   {Professor Michael G.~Dyer}
        \item Area of Study: Computational Linguistics
        \end{innerlist}

\item[] B.S.,
        \href{http://www.cs.ucla.edu/}
             {Computer Science}, December 2007
        \begin{innerlist}
          \item Computer Science
          \item Minor in Mathematics
        \end{innerlist}

\end{outerlist}

\section{Research Experience}

\href{http://www.llnl.gov/}{\textbf{Lawrence Livermore National Lab}},
Livermore, California USA
\begin{outerlist}

\item[] \textbf{Ensemble Clustering and Word Sense Induction} \\
        June 2011 - \textit{present} \\
        Advisor: \textit{David Buttler} \\

        Ensemble Clustering is a new approach that combines together multiple
        clustering models into a single ensemble approach that closely matches
        ensemble methods in supervised learning.  I am applying these Ensemble
        Clustering approaches to the task of Word Sense Induction in order to
        both leverage gains in existing state of the art methods and gain a
        better understanding of why existing models fail on current shared
        tasks.  Using this approach, I've found that existing models fail to
        perform adequately on shared tasks due to a general lack of accuracy
        and developed new semantic measures.  Using these new semantic measures,
        I intend to show that current tasks fail to measure the value of Word
        Sense Induction models appropriately and need to be significantly redesigned.

\item[] \textbf{and Topic Model Evaluation} \\
        June 2011 - \textit{present} \\
        Advisor: \textit{David Buttler} \\

        I evaluated three topic models with two recently developed coherence
        metrics that have been closely associated with human judgements.  Our
        current results indicate that the coherence metrics, originally designed
        for Latent Dirichlet Allocation, can be applied to other techniques such
        as Non-negative Matrix Factorization and Singular Value
        Decomposition, as seen in Latent Semantic Analysis).  Furthermore,
        we are evaluating new aggregate metrics for comparing entire models,
        rather than just individual topics. \\

        Based on the above research, I am beginning to investigate the
        applicability of these coherence metrics as an intrinsic evaluation of
        Word Sense Induction (WSI) models.  Current evaluation strategies for
        WSI focus on costly human judgements and do not provide a method for
        improving the models.  Along these lines, I am also Consensus Clustering
        as an evaluation of the feature space used in WSI models and the
        stability of clustering models used to differentiate word senses. \\

\item[] \textbf{Ontology Expansion} \\
        June 2010 - September 2010 \\
        Advisor: \textit{David Buttler} \\

        With David Buttler, I have investigated methods of automatically
        enhancing existing concept hierarchies for the purpose of organizing
        unstructured text documents. This work is in coordination with my work
        in Distributional Semantics and will soon be used by several information
        retrieval tasks at the national lab. \\

\end{outerlist}

\href{http://www.cs.ucla.edu/}{\textbf{University of California, Los Angeles}},
Los Angeles, California USA
\begin{outerlist}

\item[] \textbf{Distributional Semantics} \\
        September 2008 - June 2011 \\
        Advisor: \textit{Michael G.~Dyer} \\

        Distributional semantics assumes that the semantics of words can be
        defined by the contexts in which they occur, an idea proposed by Firth
        in 1957. The learned semantics have been shown to approximate semantic
        judgements made by humans on psychological and standardized tests. My
        research in this field has three main goals. \\

        First, models for distributional semantics have been developed in a
        variety of fields, such as Computational Linguistics, Cognitive Science,
        and Artificial Intelligence. In order to permit accurate evaluation of
        distinct models, a common framework is needed for their implementation
        and evaluation. To this end, I have collaborated with David Jurgens to
        develop the S-Space Package, a java based framework for implementing,
        testing, and extending distributional models. \\

        Second, current distributional models are incapable of distinguishing
        between distinct meanings for a single word, for example, “cat” can
        refer to feline pets, large felines found in the wild, or a brand of
        construction vehicles. To learn these differences, I combine
        distributional models with clustering techniques. Initial research in
        this field, Word Sense Induction, has already been shown
        to perform well according to one measure in a coordinated semantic task,
        SemEval, and to be applicable towards detecting the occurrence of news
        worthy events. \\

        Lastly, current distributional models lack organization. Word semantics
        are unorganized and disconnected from each other. In contrast, concept
        hierarchies provide a rich set of relationships between the semantics
        associated with many words. I investigate methods of combining
        distributional models and Word Sense Induction models for the purpose of
        automatically building concept hierarchies. For this, I focus on two
        approaches: extending existing hierarchies by enhancing current
        semi-supervised techniques and inferring hierarchies automatically
        from word semantics learned through only distributional methods.

\end{outerlist}

% Add a little space to nudge next ``Conference Publications'' marginpar
% down to make room for tall ``Submitted Journal Publications''
% marginpar. If there are enough submitted journal publications, this
% space will not be needed (and should be removed).
\vspace{0.1in}

\section{Publications}

\textbf{Referred} \\

\begin{bibsection}
  \item Keith Stevens, ``Evaluating Unsupervised Ensembles when applied to Word
        Sense Induction.'' to appear in \emph{Association of Computational
        Linguistics Student Research Workshop 2012}.
  \item Keith Stevens, Terry Huang and David Buttler, ``The C-Cat Wordnet
        Package: An Open Source Package for modifying and applying Wordnet.''
        \emph{Systems Demonstration of the Global Wordnet Conference 2012},
        2012.

  \item David Jurgens and Keith Stevens, ``Measuring the Impact of Sense
        Similarity on Word Sense Induction.'' \emph{Proceedings of the EMNLP 2011
        Workshop on Unsupervised Learning in NLP}, 2011. ACL.

  \item David Jurgens and Keith Stevens. ``Capturing Nonlinear Structure in Word
        Spaces Through Dimensionality Reduction.'' \emph{Proceedings of the ACL 2010
        Workshop on GEometrical Models of Natural Language Semantics}, 2010.

  \item David Jurgens and Keith Stevens. ``HERMIT: Flexible Clustering for the
        SemEval-2 WSI Task.'' \emph{Proceedings of the ACL 2010 SemEval-2010
        Workshop}, 2010.

  \item David Jurgens and Keith Stevens. ``The S-Space Package: An Open-Source
        Framework for Word Space Algorithms.'' \emph{Proceedings of the ACL 2010
        System Demonstrations}, 2010.

  \item David Jurgens and Keith Stevens. ``Event Detection in Blogs using
        Temporal Random Indexing.'' \emph{In Proceedings of the International
        Workshop on Events on Emerging Text Types} (eETTs), pages 21-28, 2009. \\

\end{bibsection} 

\textbf{Manuscripts} \\

\begin{bibsection}
  \item David Jurgens and Keith Stevens. ``Word Ordering with Reduced
        Dimensionality for Sense Induction.'' Technical Report 090020,
        University of California Los Angeles, 2009.

  \item Keith Stevens. ``Extending Word Sense Induction with waiting and
        depending.'' Masters Thesis, University of California Los Angeles,
        2010. \\

\end{bibsection} 

\section{Teaching Experience}

\href{http://www..ucla.edu}{\textbf{University of California, Los Angeles}},
Los Angeles, California USA
\begin{outerlist}

\item[] \textbf{Computer Science 32 - Introduction to Computer Science II } \\
        Teaching Assistant, \textit{Winter 2009} \textit{Spring 2009} \\

        This course introduces students to basic object oriented design a
        fundamental data structures.  Topics include C++ classes, C++ templates,
        pointer management, trees and traversal methods, inheritance, and
        recursion.  As the teaching assistant, I was responsible for teaching a
        weekly 2 hour discussion section that reviewed class lectures and broke
        down class assignments.

\item[] \textbf{Computer Science 35L - Software Construction Laboratory} \\
        Teaching Assistant, \textit{Fall 2008} \textit{Fall 2009} \\

        This course introduces students to fundamental concepts for developing
        software in a unix environment.  Topics include Bash and Python
        scripting, The GNU debugger, basic C programming, version control,
        network security, and basic operating system tools.  As the teaching
        assistant, I was responsible for all lectures and lab assignments.

\item[] \textbf{Computer Science 111 - Introduction to Operating System
                                       Principles} \\
        Teaching Associate, \textit{Spring 2010} \textit{Fall 2010} \\

        This course introduces students to the basic theories behind modern
        operating systems, with a focus on theories behind the Linux Kernel.
        Topics include concurrency, device management, file systems, memory
        management, process and thread management, Remote Procedure Calls,
        scheduling, security and protection, and shell design.  As the teaching
        assistant, I applied theories taught in class to a six lab assignments
        that covered virtual memory, process management, kernel modules, shell
        design, file systems, and remote applications.  

\item[] \textbf{Computer Science 132 - Modern Compiler Construction} \\
        Teaching Associate, \textit{Winter 2011} \\

        This course introduces students to the theories and practices behind
        compiler design.  Students learn topics focusing on parsing, type
        checking, register allocation, and virtual machines. As the teaching
        assistant, I applied theories taught in lectures to practical examples
        of compilers and assisted students with lab assignments, along with
        grading of all lab assignments.
        
\item[] \textbf{Engineering 183 - Engineering and Society} \\
        Teaching Associate, \textit{Winter 2011} \\

        This course introduces students to professional and ethical
        considerations experienced in engineering positions. 
        Emphasis is placed on the impact of technology on society and the
        development of moral and ethical values. This course also serves as the
        technical writing course for the School of Engineering. Lectures cover
        ethical topics, while teaching assistant-led sections cover technical
        writing. \\

        I taught a weekly three-hour discussion on technical writing and ethics.
        As the teaching assistant, I covered all writing requirements for
        students and provided a series of writing exercises designed to improve
        their ability to concisely describe, evaluate, and solve ethical
        dilemmas in Engineering. \\

\end{outerlist}

\section{Professional Experience}

\href{http://www.llnl.gov}{\textbf{Lawrence Livermore National Lab}}, 
Livermore, CA
\begin{outerlist}

\item[] \textit{Student Research Intern},
        \textbf{June 2010 to September 2010}\\
        Mentor: \textit{David Buttler} \\

        \begin{innerlist}
        \item Implemented an existing taxonomy expansion algorithm for a highly
              distributed framework based on Hadoop and HBase
        \item Implemented several methods for condensing an existing taxonomy
        \item Evaluateedseveral methods for integrating taxonomy induction and
              condensation techniques
        \item Evaluated several methods for enhancing taxonomy expansion
              and condensation methods such that the resulting taxonomy is
              customized for a particular domain of knowledge
        \item Developed a new, java based interface for the widely used WordNet
              taxonomy \\
       \end{innerlist}
\end{outerlist}

\href{http://www.google.com}{\textbf{Google, Inc.}}, 
Kirkland, WA
\begin{outerlist}

\item[] \textit{Software Engineering Intern},
        \textbf{June 2009 to September 2009}\\
        Mentor: \textit{Zhen Lin} \\

        \begin{innerlist}
        \item Enhanced a document selection system with the addition of semantic
              analysis.  This analysis provided a more detailed representation
              of the document, as it changed over several points in time. This
              analysis allowed the application to inform users of more relevant
              aspects of the page.
        \item Enhanced crawling framework for the document selection system,
              improving savings by up to 50\% usage of external resources.
        \item Restructured document selection system to be more scalable and
              abide by internal policies.
        \end{innerlist}

\item[] \textit{Software Engineering Intern},
        \textbf{January 2008 to September 2008}\\
        Mentor: \textit{Hizakazu Igarashi} \\

        \begin{innerlist}
        \item Built a highly scalable, stateless server for responding to a wide
              variety, and high volume, of requests.
        \item Developed several plugins for the designed server allowing access
              to a wide variety of data sources.
        \item Improved serving time of the server by addition of caching
              responses in memory
        \item Improved response time of a query formulation system with the use
              of a Trie, and integration as a plugin for the server.
        \item Heavily unittested, document, and debugged same server. \\
        \end{innerlist}

\end{outerlist}

\halfblankline

\href{http://nesl.ee.ucla.edu/}{\textbf{Networked and Embedded Systems Laboratory}}, 
Los Angeles, CA
\begin{outerlist}

\item[] \textit{Student Research Intern},
        \textbf{March 2007 to December 2007}\\
        Mentor: \textit{Professor Mani Srivastava} \\

        \begin{innerlist}
        \item Designed multiple modules for use on a Micaz/Mica2 sensor board
              using the SOS embedded operating system, which is based on a
              Linux architecture.
        \item Reduced the transmission rate of nodes by defining a time series
              representing sensor values.
        \item Designed a unit test framework for the SOS operating system.
        \end{innerlist}
\end{outerlist}

\section{Open Source Projects}

\href{https://github.com/fozziethebeat/S-Space}{\textbf{The S-Space Package}} \\

The S-Space package is an open source package written in Java for building and
evaluating word space algorithms learned from word distributions. The package
includes reference implementations of frequently cited algorithms, specialized
data structures for natural language processing, and multi- threaded matrix
implementations for concurrent algorithms. It also now includes a framework for
building Word Sense Induction algorithms and a growing library of clustering
algorithms. \\

I work on this this project as a primary contributor with David Jurgens.  This
package is being developed as a part of my research, and makes all of the
software used for my research freely available.  The project is available on
GitHub at www.github.com/fozziethebeat/S-Space \\

\halfblankline

\href{https://github.com/fozziethebeat/C-Cat}{\textbf{The C-Cat Package}} \\

The C-Cat package provides three key features for processing large corpora over
the Hadoop MapReduce  framework : text processing utilies such as parsing,
tokenization, and sentence detection; a new WordNet API that facilitates direct
modification of the lexical ontology; and new APIS and MapReduce codes to
automatically extend or reduce an ontology based on distributional information.
\\

This project was developed while I worked for Lawrence Livermore National
Lab.  It also serves as a staging ground for MapReduce based word space
implementations based on those in the S-Space package.  I am the primary
contributor.  The project is available on GitHub at
www.github.com/fozziethebeat/S-Space \\

\halfblankline

\section{Service}

\textbf{The Computer Science Graduate Student Committe} \\

Contributing member of a UCLA graduate student group dedicated to improving the
academic and social lives of computer science graduate students. My
contributions include \\

\begin{innerlist}
  \item Organizing and advertising for a presentation competition called
  \textit{So You Think You Can present}: \textbf{\$CONTEST} aimed at having
  graduate students talk about exciting research ideas in front of large
  audiences.
  \item Organizing for bi-annual department picnics.
  \item Organizing for weekly tea-times.
  \item Mentoring incoming Masters and PhD students.
\end{innerlist}

\halfblankline

\textbf{The Engineering Graduate Student Association} \\

Board member of a UCLA Engineering Graduate Student Association, a student group
dedicated to improving the academic and social lives of engineering graduate
students. I served as the \textit{Sustainability Chair}, my contributions
include \\

\begin{innerlist}
  \item Attending meetings with other student groups to discuss current
  sustainability practices at UCLA.
  \item Organizing and managing a quarterly Engineering Social.
  \item Organizing information sessions.
\end{innerlist}

\halfblankline

\textbf{UAW Local 2864} \\

Head Steward of the UAW Local 2865, the union representing Teaching Assistants,
Readers and Graders for all schools in the University of California system.  My
responsibilities include \\

\begin{innerlist}
  \item Organizing an election campaign.
  \item Managing the UCLA unit's blog.
  \item Representing engineers in quarterly union wide meetings.
  \item Organizing and presenting for information sessions to raise awareness
  and interest in the union.
\end{innerlist}

\halfblankline

\textbf{The University Buddhist Association} \\

The UBA provides an open non-sectarian group for students that are practicing
Buddhism or interested in learning more about the religion.  I served as a
leading member to organize socials, field trips to monasteries and temples, and
connect with other Buddhist groups in Southern California. \\


\section{Mentoring}

\begin{outerlist}

\item[] Sky Lin, Grace Park, and Alex Nau, 2009 \\
        I worked closely with three students as a part of the CS 199 Course:
        Directed Research in Computer Science. As their mentor, I helped select
        and conduct several concen- trated research tasks in Distributional
        Semantics. Their work focused on implementing and evaluating useful
        distributional models and has been incorporated into the S-Space Package

\item[] Alexander Honda, 2010 \\
        I worked with Alexander on two tasks: examining feature importance in
        word-space models and studying topic modelling. This work was done as a
        part of the CS 199 Course: Directed Research in Computer Science.

\item[] David Cohen, 2010 \\
        I worked with David on extending lexical ontologies with word-space
        models. This work was done as a part of the CS 199 Course: Directed
        Research in Computer Science. 

\item[] Terry Huang, 2011 \\
        I mentored Terry Huang in the Winter and Spring quarters of 2011 to
        build an open source implementation of the Castanet algorithm, an
        automated method of learning hierarchical facets for a document set
        based on distributional information and the WordNet lexical ontology.
        Since the summer, we have been incorporating it into the C-Cat package
        and co-authored a recent paper submitted to the Global Wordnet
        Conference of 2012.

\end{outerlist}

\section{Patents}

``Semantic Document Analysis,'' with Zhen Lin. FR16113-2118P01; GP-2700-00-PR \\

``Efficient scheduling of webpage crawls,'' with Zhen Lin. FR16113-2119P01;
GP-269900-PR

\section{References}

\textit{Available upon request}

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%% End CV Document %%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------%
% The following is copyright and licensing information for
% redistribution of this LaTeX source code; it also includes a liability
% statement. If this source code is not being redistributed to others,
% it may be omitted. It has no effect on the function of the above code.
%----------------------------------------------------------------------%
% Copyright (c) 2007, 2008, 2009, 2010, 2011 by Theodore P. Pavlic
%
% Unless otherwise expressly stated, this work is licensed under the
% Creative Commons Attribution-Noncommercial 3.0 United States License. To
% view a copy of this license, visit
% http://creativecommons.org/licenses/by-nc/3.0/us/ or send a letter to
% Creative Commons, 171 Second Street, Suite 300, San Francisco,
% California, 94105, USA.
%
% THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
% OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
% MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
% IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
% CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
% TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
% SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
%----------------------------------------------------------------------%
